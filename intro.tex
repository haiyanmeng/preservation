\section{Introduction}

Reproducibility is a cornerstone of the scientific method~\cite{borgman2012data}. 
Its importance is underscored by its ability to advance science---reproducing by verifying and validating a scientific result leads to improved understanding, thus increasing possibilities of reusing or extending the result. 
Ensuring reproducibility of a scientific result, however, often entails detailed documentation and specification of the involved scientific method. Historically, this has been achieved through text and proofs in a publication. 
As computation pervades the sciences and transforms the scientific method, mere text is no longer sufficient. 
In particular, apart from textual descriptions describing the result, a reproducible result must also include several computational artifacts, such as software, data,  environment variables, and state of computation that are involved in the adopted scientific method \cite{Sole}.  

Virtualization has emerged as a promising approach for reproducing computational scientific results. One approach is to conduct the entire computation relating to a scientific result within a virtual machine image, and then share the resulting image. This way VMIs become an authoritative, encapsulated, and executable records of computations, especially computations whose results are destined for publication and/or re-use, and the VMIs can be shared easily \cite{Lampoudi}. 
However, the resulting image may be too big to distribute. An alternative light-weight form of virtualization allows encapsulation of the application software, along with all its necessary dependencies into a self-contained package, but does not make it executable.
The encapsulation of the self-contained package is achieved by interposing application system calls, and copying the necessary dependencies (data, libraries, code, etc.) into the package, making it lighter weight than a VMI~\cite{guo2011cde}. While both approaches provide mechanisms for sandboxing the computations associated with a scientific result, neither form of virtualization provides any guarantee that the included pieces of software will indeed reproduce the associated scientific result. 

Since reproducibility includes documentation, virtualization approaches in their current form only make it easy to capture the computations. Preserving the computations so that they are easy to understand, install, or alter implicit dependencies that are part of computation is not effectively addressed, especially as dependencies and software components evolve or become deprecated. There are two approaches to address the preservation challenge. By either introducing tools that help document dependencies and provide software attribution within VMIs or packages, or alternatively by using software delivery mechanisms, such as, centralized package management, Linux containers, and the, more recent, Docker framework. We examined the first approach previously in \cite{SoftProv}. 
In this paper we examine the second approach. 
In particular, we consider the light-weight virtualization approaches, because, we believe that the combination of light-weight approaches with more standardized software delivery mechanisms can lead to addressing the reproducibility challenge for a wide variety of scientific researchers. 
A package created by those light-weight approaches encapsulates all the necessary dependencies of an application, and can be used to repeat the application through different sandbox mechanisms, including Parrot~\cite{thain2005parrot}, CDE, PTU~\cite{PTU}, chroot, and Docker~\cite{boettiger2015introduction}.

We do not claim our solution is the only way to preserve applications. Generally, there are two different approaches to preserve applications: measure the mess and force cleanliness. The first approach allows end users to construct the environment as desired, and then measures the dependencies. The latter one forces users to specify the execution environment for an application in a well organized way.
Our objective here is to preserve the mess as-is.

To conduct a thorough examination, we consider real-world complex high energy physics (HEP) applications, independently developed by two groups, that must be reproduced so that the entire HEP community can benefit from the analysis. We describe challenges in reproducing the applications, and consider the extent to which reproducibility requirements can be satisfied with light-weight virtualization approaches and software delivery mechanisms. We propose an invariant framework for computational reproducibility that combines light-weight virtualization with software delivery mechanisms for efficiently capturing, invariantly preserving and practically deploying applications.
We measure the performance overhead of  light-weight virtualization and software delivery approaches, and show the preserved packages can be distributed to allow reproduction and verification.

